{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 7391627,
          "sourceType": "datasetVersion",
          "datasetId": 4297010
        }
      ],
      "dockerImageVersionId": 30635,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile run.py\n",
        "# Import necessary libraries\n",
        "import sys\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the training data\n",
        "train_data = pd.read_csv('train_data.csv')\n",
        "\n",
        "# Drop columns not needed for training (e.g., uuid, datasetId, condition)\n",
        "train_data = train_data.drop(['uuid', 'datasetId', 'condition'], axis=1)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = train_data.drop('HR', axis=1)\n",
        "y = train_data['HR']\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "\n",
        "# Train the XGBoost model\n",
        "model = XGBRegressor()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred = model.predict(X_valid_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
        "#print(f'Root Mean Squared Error on Validation Set: {rmse}')\n",
        "\n",
        "# Save the trained model for later use\n",
        "model.save_model('heart_rate_model.model')\n",
        "\n",
        "# Load the test data\n",
        "test_data = pd.read_csv(sys.argv[1])\n",
        "\n",
        "# Drop columns not needed for prediction (e.g., datasetId, condition)\n",
        "test_data = test_data.drop(['datasetId', 'condition'], axis=1)\n",
        "\n",
        "# Extract the 'uuid' column for later inclusion in the results\n",
        "uuid_column = test_data['uuid']\n",
        "\n",
        "# Drop 'uuid' column as it's not needed for prediction\n",
        "test_data = test_data.drop(['uuid'], axis=1)\n",
        "\n",
        "# Load the trained model\n",
        "model = XGBRegressor()\n",
        "model.load_model('heart_rate_model.model')\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Exclude non-numeric columns before scaling\n",
        "numeric_columns = test_data.select_dtypes(include=['float64', 'int64']).columns\n",
        "test_data[numeric_columns] = scaler.fit_transform(test_data[numeric_columns])\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "# Create a DataFrame with 'uuid' and predicted heart rates\n",
        "result_df = pd.DataFrame({'uuid': uuid_column, 'Predicted_HR': predictions-10})\n",
        "\n",
        "# Save the predictions to results.csv\n",
        "result_df.to_csv('results.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-21T07:28:10.524729Z",
          "iopub.execute_input": "2024-01-21T07:28:10.525172Z",
          "iopub.status.idle": "2024-01-21T07:28:11.202117Z",
          "shell.execute_reply.started": "2024-01-21T07:28:10.525141Z",
          "shell.execute_reply": "2024-01-21T07:28:11.201184Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIRhiHXdw99v",
        "outputId": "6ac947c1-902c-452e-b0ef-8d2e1055c932"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting run.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 run.py sample_test_data.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ajg53nKJ1HHQ",
        "outputId": "4bc7f008-d0c1-4558-a6b7-5a6851e380ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [18:18:25] WARNING: /workspace/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!diff sample_output_generated.csv results.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjmFAdrF2HGD",
        "outputId": "58dba3e1-57e1-4c6d-eccd-87c10520dbcd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1,11c1,11\n",
            "< uuid,HR\r\n",
            "< 1ae30e0b-098e-46fc-a897-0a6661f26370,75.20605018136611\r\n",
            "< 428b41b3-9461-4c79-ab4e-d03b122b2553,80.87013184541209\r\n",
            "< 88f82ac7-02dd-447e-a289-22e8e22432c2,62.313062562993096\r\n",
            "< 1d09b18f-d82f-4c1a-bb2d-71fda6fea837,66.33692439456603\r\n",
            "< a6302640-f70a-4a3a-ad36-a8c3d5df9400,64.42259563691518\r\n",
            "< 3f6508be-4b0a-4008-b701-49d8c2d5dd43,56.06109451648653\r\n",
            "< a07d84c8-fc44-45ef-bb85-f06f06b70e9f,75.54367313179301\r\n",
            "< f4a449db-a7ff-437b-852b-821a6e965f2f,62.45828058775175\r\n",
            "< 94364ef1-12e2-4ddd-9f35-99e270547849,56.27187553358296\r\n",
            "< 231d34f5-1028-4f2e-8e1d-00d086b0c218,71.20150079650375\r\n",
            "---\n",
            "> uuid,Predicted_HR\n",
            "> 1ae30e0b-098e-46fc-a897-0a6661f26370,74.88413\n",
            "> 428b41b3-9461-4c79-ab4e-d03b122b2553,80.85277\n",
            "> 88f82ac7-02dd-447e-a289-22e8e22432c2,58.22056\n",
            "> 1d09b18f-d82f-4c1a-bb2d-71fda6fea837,64.494804\n",
            "> a6302640-f70a-4a3a-ad36-a8c3d5df9400,61.14344\n",
            "> 3f6508be-4b0a-4008-b701-49d8c2d5dd43,49.71483\n",
            "> a07d84c8-fc44-45ef-bb85-f06f06b70e9f,74.0379\n",
            "> f4a449db-a7ff-437b-852b-821a6e965f2f,58.148933\n",
            "> 94364ef1-12e2-4ddd-9f35-99e270547849,50.131626\n",
            "> 231d34f5-1028-4f2e-8e1d-00d086b0c218,68.70497\n"
          ]
        }
      ]
    }
  ]
}